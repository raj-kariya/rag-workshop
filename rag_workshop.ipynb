{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 11124599,
          "sourceType": "datasetVersion",
          "datasetId": 6937541
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "rag_workshop",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raj-kariya/rag-workshop/blob/main/rag_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "To4UF9vydXpd"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "rajkariya_sampled_reviews_path = kagglehub.dataset_download('rajkariya/sampled-reviews')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "ou1SUukjdXph"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:38:54.320805Z",
          "iopub.execute_input": "2025-03-22T08:38:54.321143Z",
          "iopub.status.idle": "2025-03-22T08:38:54.766678Z",
          "shell.execute_reply.started": "2025-03-22T08:38:54.321117Z",
          "shell.execute_reply": "2025-03-22T08:38:54.76549Z"
        },
        "id": "Pd_4ZcCzdXpi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# we are going to study RAG\n",
        "input_path = '/kaggle/input/sampled-reviews/sampled_reviews.csv'\n",
        "data = pd.read_csv(input_path)\n",
        "data"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:38:57.39847Z",
          "iopub.execute_input": "2025-03-22T08:38:57.399006Z",
          "iopub.status.idle": "2025-03-22T08:38:57.496467Z",
          "shell.execute_reply.started": "2025-03-22T08:38:57.398968Z",
          "shell.execute_reply": "2025-03-22T08:38:57.495188Z"
        },
        "id": "gTxzkOXydXpi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sparse Retrieval"
      ],
      "metadata": {
        "id": "BLKnkxWodXpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:39:23.367877Z",
          "iopub.execute_input": "2025-03-22T08:39:23.368283Z",
          "iopub.status.idle": "2025-03-22T08:39:23.975552Z",
          "shell.execute_reply.started": "2025-03-22T08:39:23.36825Z",
          "shell.execute_reply": "2025-03-22T08:39:23.97425Z"
        },
        "id": "ZOztLFxcdXpk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "documents = data['combined'].tolist()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:39:47.669724Z",
          "iopub.execute_input": "2025-03-22T08:39:47.670205Z",
          "iopub.status.idle": "2025-03-22T08:39:47.676618Z",
          "shell.execute_reply.started": "2025-03-22T08:39:47.670143Z",
          "shell.execute_reply": "2025-03-22T08:39:47.67522Z"
        },
        "id": "_57rdj-9dXpk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"TF-IDF matrix shape:\", tfidf_matrix.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:40:00.741094Z",
          "iopub.execute_input": "2025-03-22T08:40:00.741676Z",
          "iopub.status.idle": "2025-03-22T08:40:01.005011Z",
          "shell.execute_reply.started": "2025-03-22T08:40:00.741637Z",
          "shell.execute_reply": "2025-03-22T08:40:01.003498Z"
        },
        "id": "WbLeXJoqdXpl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(\"Number of features:\", len(feature_names))\n",
        "print(\"Some feature names:\", feature_names[:10])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:40:10.925105Z",
          "iopub.execute_input": "2025-03-22T08:40:10.925473Z",
          "iopub.status.idle": "2025-03-22T08:40:10.939282Z",
          "shell.execute_reply.started": "2025-03-22T08:40:10.925446Z",
          "shell.execute_reply": "2025-03-22T08:40:10.937794Z"
        },
        "id": "VJM-Os5cdXpl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dense_rep = tfidf_matrix.toarray()\n",
        "print(\"\\nTF-IDF vector for first document:\")\n",
        "print(dense_rep[0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:40:31.232111Z",
          "iopub.execute_input": "2025-03-22T08:40:31.232524Z",
          "iopub.status.idle": "2025-03-22T08:40:31.47601Z",
          "shell.execute_reply.started": "2025-03-22T08:40:31.232491Z",
          "shell.execute_reply": "2025-03-22T08:40:31.474828Z"
        },
        "id": "s_-Z0l9sdXpl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:42:02.646972Z",
          "iopub.execute_input": "2025-03-22T08:42:02.647387Z",
          "iopub.status.idle": "2025-03-22T08:42:08.843615Z",
          "shell.execute_reply.started": "2025-03-22T08:42:02.647355Z",
          "shell.execute_reply": "2025-03-22T08:42:08.842182Z"
        },
        "id": "1UhA1_AVdXpm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "documents = data['combined'].tolist()\n",
        "\n",
        "tokenized_docs = [doc.lower().split() for doc in documents]\n",
        "\n",
        "bm25 = BM25Okapi(tokenized_docs)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:42:08.845487Z",
          "iopub.execute_input": "2025-03-22T08:42:08.845908Z",
          "iopub.status.idle": "2025-03-22T08:42:08.972178Z",
          "shell.execute_reply.started": "2025-03-22T08:42:08.845868Z",
          "shell.execute_reply": "2025-03-22T08:42:08.970975Z"
        },
        "id": "j4ae6Zs1dXpm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"bm25 retrieval function\"\n",
        "\n",
        "query_tokens = query.lower().split()\n",
        "\n",
        "scores = bm25.get_scores(query_tokens)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "for i, score in enumerate(scores):\n",
        "    print(f\"Doc {i} score: {score:.4f} -> {documents[i]}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:43:09.520421Z",
          "iopub.execute_input": "2025-03-22T08:43:09.52139Z",
          "iopub.status.idle": "2025-03-22T08:43:09.956016Z",
          "shell.execute_reply.started": "2025-03-22T08:43:09.521231Z",
          "shell.execute_reply": "2025-03-22T08:43:09.949954Z"
        },
        "id": "bznnQ5BldXpm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "inverted_index = {}\n",
        "\n",
        "for term_idx, term in enumerate(feature_names):\n",
        "    col = tfidf_matrix[:, term_idx]\n",
        "    doc_ids = col.nonzero()[0]  # equivalent to col.indices\n",
        "    inverted_index[term] = list(doc_ids)\n",
        "\n",
        "# --------------------------------------------\n",
        "# Print Inverted Index\n",
        "# --------------------------------------------\n",
        "print(\"\\n=== Inverted Index ===\")\n",
        "# for term, doc_list in inverted_index.items():\n",
        "#     print(f\"{term}: {doc_list}\")\n",
        "\n",
        "# --------------------------------------------\n",
        "# Example Query\n",
        "# --------------------------------------------\n",
        "query_terms = [\"food\", \"dog\"]\n",
        "matched_docs = {}\n",
        "\n",
        "for term in query_terms:\n",
        "    if term in inverted_index:\n",
        "        for doc_id in inverted_index[term]:\n",
        "            matched_docs[doc_id] = matched_docs.get(doc_id, 0) + 1\n",
        "\n",
        "# Sort documents by number of matching query terms\n",
        "ranked_results = sorted(matched_docs.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(f\"\\nQuery: {query_terms}\")\n",
        "print(\"Ranked Matching Documents:\")\n",
        "for doc_id, match_count in ranked_results:\n",
        "    print(f\"Doc {doc_id} (matches: {match_count}) -> {documents[doc_id]}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:42:42.541264Z",
          "iopub.execute_input": "2025-03-22T08:42:42.541793Z",
          "iopub.status.idle": "2025-03-22T08:42:49.818555Z",
          "shell.execute_reply.started": "2025-03-22T08:42:42.541756Z",
          "shell.execute_reply": "2025-03-22T08:42:49.811371Z"
        },
        "id": "XzJY8T01dXpm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "BM 25 method takes worst came O(m^2) which is very bad if you deploy it in production and you wont able to give to give recommended products to users on time."
      ],
      "metadata": {
        "id": "K7bZ1vnxdXpm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now comes transformers which will decreasee the complexity"
      ],
      "metadata": {
        "id": "loYS1-qUdXpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dense Passage Retriever (DPR)"
      ],
      "metadata": {
        "id": "Rzo3c-WFdXpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:51:47.121828Z",
          "iopub.execute_input": "2025-03-22T08:51:47.122284Z",
          "iopub.status.idle": "2025-03-22T08:51:51.681653Z",
          "shell.execute_reply.started": "2025-03-22T08:51:47.122252Z",
          "shell.execute_reply": "2025-03-22T08:51:51.680295Z"
        },
        "id": "Pewpx6ZzdXpn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:56:08.52156Z",
          "iopub.execute_input": "2025-03-22T08:56:08.521903Z",
          "iopub.status.idle": "2025-03-22T08:56:14.949757Z",
          "shell.execute_reply.started": "2025-03-22T08:56:08.521875Z",
          "shell.execute_reply": "2025-03-22T08:56:14.948355Z"
        },
        "id": "IywrxI2jdXpn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
        "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
        "from sentence_transformers.util import cos_sim\n",
        "import faiss\n",
        "import torch\n",
        "\n",
        "\n",
        "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
        "question_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
        "\n",
        "passage_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "passage_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "question_encoder = question_encoder.to(device)\n",
        "passage_encoder = passage_encoder.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:56:17.268621Z",
          "iopub.execute_input": "2025-03-22T08:56:17.268984Z",
          "iopub.status.idle": "2025-03-22T08:57:06.817881Z",
          "shell.execute_reply.started": "2025-03-22T08:56:17.268956Z",
          "shell.execute_reply": "2025-03-22T08:57:06.816496Z"
        },
        "id": "kpsj5rvgdXpn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # -------------------------------\n",
        "# # Encode Passages with DPR Context Encoder\n",
        "# # -------------------------------\n",
        "# def encode_passages(passages):\n",
        "#     inputs = passage_tokenizer(passages, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n",
        "#     with torch.no_grad():\n",
        "#         embeddings = passage_encoder(**inputs).pooler_output  # shape: (n_docs, hidden_size)\n",
        "#     return embeddings.cpu().numpy()\n",
        "\n",
        "# passage_embeddings = encode_passages(documents)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T08:59:01.682429Z",
          "iopub.execute_input": "2025-03-22T08:59:01.682871Z",
          "iopub.status.idle": "2025-03-22T09:01:25.890843Z",
          "shell.execute_reply.started": "2025-03-22T08:59:01.682832Z",
          "shell.execute_reply": "2025-03-22T09:01:25.88827Z"
        },
        "id": "fVJCZbi9dXpn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:01:37.240106Z",
          "iopub.execute_input": "2025-03-22T09:01:37.240527Z",
          "iopub.status.idle": "2025-03-22T09:01:44.741841Z",
          "shell.execute_reply.started": "2025-03-22T09:01:37.240494Z",
          "shell.execute_reply": "2025-03-22T09:01:44.740515Z"
        },
        "id": "YzfuOzZ4dXpn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:01:49.467346Z",
          "iopub.execute_input": "2025-03-22T09:01:49.467741Z",
          "iopub.status.idle": "2025-03-22T09:01:49.473602Z",
          "shell.execute_reply.started": "2025-03-22T09:01:49.467703Z",
          "shell.execute_reply": "2025-03-22T09:01:49.472044Z"
        },
        "id": "hFULRMlTdXpn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_passages_batched(passages, batch_size=8):\n",
        "    all_embeddings = []\n",
        "\n",
        "    for i in tqdm(range(0, len(passages), batch_size)):\n",
        "        batch_passages = passages[i:i + batch_size]\n",
        "        inputs = passage_tokenizer(batch_passages, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = passage_encoder(**inputs)\n",
        "            embeddings = outputs.pooler_output  # shape: (batch_size, hidden_size)\n",
        "\n",
        "        all_embeddings.append(embeddings.cpu())\n",
        "\n",
        "    return torch.cat(all_embeddings, dim=0).numpy()\n",
        "\n",
        "passage_embeddings = encode_passages_batched(documents, batch_size=128)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:01:52.038578Z",
          "iopub.execute_input": "2025-03-22T09:01:52.038916Z",
          "iopub.status.idle": "2025-03-22T09:37:18.764787Z",
          "shell.execute_reply.started": "2025-03-22T09:01:52.038891Z",
          "shell.execute_reply": "2025-03-22T09:37:18.761472Z"
        },
        "id": "f6o2R1kFdXpn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "spotify annoy library for search"
      ],
      "metadata": {
        "id": "VjPpuPnqdXpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COLBERT"
      ],
      "metadata": {
        "id": "lmWzpqZOdXpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"doc_id\"] = data.index\n",
        "data = data[[\"doc_id\", \"combined\"]]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:39:03.342222Z",
          "iopub.execute_input": "2025-03-22T09:39:03.342625Z",
          "iopub.status.idle": "2025-03-22T09:39:03.434501Z",
          "shell.execute_reply.started": "2025-03-22T09:39:03.342597Z",
          "shell.execute_reply": "2025-03-22T09:39:03.433329Z"
        },
        "id": "FQaXVuOzdXpo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def save_df_to_colbert_format(df, output_path, id_col=\"doc_id\", text_col=\"combined\"):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for _, row in df.iterrows():\n",
        "            doc_id = str(row[id_col])\n",
        "            text = row[text_col].replace(\"\\n\", \" \").replace(\"\\t\", \" \").strip()\n",
        "            f.write(f\"{doc_id}\\t{text}\\n\")\n",
        "\n",
        "# Save to disk\n",
        "save_df_to_colbert_format(data, \"colbert_corpus.tsv\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:39:19.682729Z",
          "iopub.execute_input": "2025-03-22T09:39:19.683121Z",
          "iopub.status.idle": "2025-03-22T09:39:19.819839Z",
          "shell.execute_reply.started": "2025-03-22T09:39:19.683091Z",
          "shell.execute_reply": "2025-03-22T09:39:19.818412Z"
        },
        "id": "-1p48tK9dXpo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ragatouille"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:39:54.268771Z",
          "iopub.execute_input": "2025-03-22T09:39:54.269127Z",
          "iopub.status.idle": "2025-03-22T09:40:12.316429Z",
          "shell.execute_reply.started": "2025-03-22T09:39:54.269099Z",
          "shell.execute_reply": "2025-03-22T09:40:12.315079Z"
        },
        "id": "qaKaEuuEdXpo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from ragatouille import RAGPretrainedModel\n",
        "\n",
        "# Load ColBERTv2\n",
        "colbert_model = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
        "\n",
        "# Define your documents\n",
        "\n",
        "\n",
        "# Index the documents\n",
        "colbert_model.index(\n",
        "    collection=documents,\n",
        "    index_name=\"my-colbert-index\",\n",
        "    max_document_length=180  # token limit per doc\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-22T09:40:20.687267Z",
          "iopub.execute_input": "2025-03-22T09:40:20.687654Z",
          "iopub.status.idle": "2025-03-22T09:45:31.143919Z",
          "shell.execute_reply.started": "2025-03-22T09:40:20.687624Z",
          "shell.execute_reply": "2025-03-22T09:45:31.142061Z"
        },
        "id": "ynEUZ34ZdXpo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "B8F00djudXpo"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}